{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import subprocess as s\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import glob\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def mkdir(path):\n",
    "    # Create relevant directory\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(data_base, analysis_base, cluster, radius=60):\n",
    "    os.chdir(data_base)\n",
    "    \n",
    "    xmm_browse = '/opt/xmm_download/./browse_extract.pl'\n",
    "    \n",
    "    f = open('check_data.txt', 'w')\n",
    "    s.run([f'{xmm_browse}', 'table=xmmmaster', f'position={cluster}', 'name_resolver=ned', f'radius={radius/60.}',\n",
    "           'format=Text'], stdout=f, stderr=f)\n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(analysis_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(obsid):    \n",
    "    xmm_download = '/opt/xmm_download/./aioclient'\n",
    "    \n",
    "    f = open('download_data.txt', 'w')\n",
    "    s.run([f'{xmm_download}', '-L', f'GET obsno={obsid} level=ODF'], stdout=f, stderr=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(obsid):    \n",
    "    # Expand the main file\n",
    "    fname = f'{obsid}.tar.gz'\n",
    "    \n",
    "    f = open('unpack_1.txt', 'w')\n",
    "    s.run([f'tar', '-xvzf', fname], stdout=f, stderr=f)\n",
    "    f.close()\n",
    "    \n",
    "    # Expand the observation file\n",
    "    fname = fname = glob.glob('*.TAR')[0]\n",
    "    \n",
    "    f = open('unpack_2.txt', 'w')\n",
    "    s.run([f'tar', '-xvzf', fname], stdout=f, stderr=f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib(data_path, analysis_path):\n",
    "    os.environ['SAS_ODF'] = data_path\n",
    "    f = open('cifbuild.txt', 'w')\n",
    "    s.run(['cifbuild'], stdout=f, stderr=f)\n",
    "    f.close()\n",
    "\n",
    "    # Set cifbuild\n",
    "    os.environ['SAS_CCF'] = analysis_path + 'ccf.cif'\n",
    "\n",
    "    # Run odfingest\n",
    "    f = open('odfingest.txt', 'w')\n",
    "    s.run(['odfingest'], stdout=f, stderr=f)\n",
    "    f.close()\n",
    "\n",
    "    # Find SAS extension and set the environment\n",
    "    os.environ['SAS_ODF'] = glob.glob(analysis_path + '*.SAS')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_environ(analysis_path):\n",
    "    # Set cifbuild\n",
    "    os.environ['SAS_CCF'] = analysis_path + 'ccf.cif'\n",
    "    \n",
    "    # Find SAS extension and set the environment\n",
    "    os.environ['SAS_ODF'] = glob.glob(analysis_path + '*.SAS')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reprocess(instrument, analysis_path, OoT=False):\n",
    "    # Create relevant directory\n",
    "    mkdir(instrument)\n",
    "\n",
    "    # Change to instrument directory\n",
    "    os.chdir(instrument)\n",
    "\n",
    "    # Keep log file in analysis directory\n",
    "    if(OoT):\n",
    "        f = open(analysis_path + '/' + instrument + '_OoT_reprocess.txt', 'w')\n",
    "    else:\n",
    "        f = open(analysis_path + '/' + instrument + '_reprocess.txt', 'w')\n",
    "    \n",
    "    # Check which instrument is requested and reprocess accordingly\n",
    "    if(instrument == 'EMOS1' or instrument == 'EMOS2'):\n",
    "        s.run(['emproc', 'selectinstruments=yes', instrument.lower()+'=yes'], stdout=f, stderr=f)\n",
    "    \n",
    "    elif(instrument == 'EPN'):\n",
    "        if(OoT):\n",
    "            #Create directory and change directory\n",
    "            mkdir('OoT')\n",
    "            os.chdir('OoT')\n",
    "            \n",
    "            # Reprocess\n",
    "            s.run(['epproc', 'withoutoftime=yes'], stdout=f, stderr=f)\n",
    "            \n",
    "            # Rename the OoT file\n",
    "            fname = glob.glob('*EPN*_ImagingEvts.ds')[0]\n",
    "            index = fname.find('ImagingEvts.ds')\n",
    "            new_fname = fname[:index] + 'OoT_' + fname[index:]\n",
    "            \n",
    "            s.run(['mv', fname, new_fname])\n",
    "            \n",
    "            # Change to instrument directory\n",
    "            os.chdir('../')\n",
    "        else:\n",
    "            # Create directory and change directory\n",
    "            mkdir('Main')\n",
    "            os.chdir('Main')\n",
    "            \n",
    "            # Reprocess\n",
    "            s.run(['epproc'], stdout=f, stderr=f)\n",
    "            \n",
    "            # Change to instrument directory\n",
    "            os.chdir('../')\n",
    "            \n",
    "    # Handle exception appropriately\n",
    "    else:\n",
    "        os.chdir('../')\n",
    "        os.unlink(f.name)\n",
    "        s.run(['rm','-r', instrument])\n",
    "        raise ValueError('Invalid instrument!!!')\n",
    "                  \n",
    "    f.close()\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc(instrument, analysis_path, bkg=False):\n",
    "    # Change to instrument directory\n",
    "    os.chdir(instrument)\n",
    "    \n",
    "    # Keep log file in analysis directory\n",
    "    f = open(analysis_path + instrument + '_lc.txt', 'w')\n",
    "    \n",
    "    # Check which instrument is requested and process accordingly\n",
    "    if(instrument == 'EPN'):\n",
    "        os.chdir('Main')\n",
    "        pattern = 4\n",
    "    else:\n",
    "        pattern = 12\n",
    "        \n",
    "    fname = glob.glob('*_ImagingEvts.ds')[0]\n",
    "\n",
    "    s.run(['evselect', f'table={fname}', 'withrateset=Y', f'rateset=rate_{instrument}.fits', \n",
    "            'maketimecolumn=Y', 'timebinsize=100', 'makeratecolumn=Y', \n",
    "            f'expression=#XMMEA_{instrument[:2]} && (PI in [9000:12000]) && (PATTERN<={pattern})'], \n",
    "          stdout=f, stderr=f)\n",
    "        \n",
    "    if(instrument == 'EPN'):\n",
    "        s.run(['cp', f'rate_{instrument}.fits', f'../OoT/rate_{instrument}.fits'])\n",
    "\n",
    "    \n",
    "    f.close()\n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and plot gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(x, y, y_err, model, xlim, ObsID, instrument, figures_path, xscale='linear', bkg=False):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8,8), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "    ax1.tick_params(direction='in', which='both', length=5, labelsize=15)\n",
    "    ax2.tick_params(direction='in', which='both', length=5, labelsize=15)\n",
    "\n",
    "    plt.suptitle('RATE')\n",
    "    \n",
    "    ax1.set_ylabel(r'N', fontsize = 15.0)\n",
    "    ax1.set_xscale(xscale)\n",
    "    \n",
    "    ax1.set_xlim(0, xlim[1])\n",
    "\n",
    "    ax1.errorbar(x, y, yerr=y_err, fmt='o', capsize=2, label='Data')\n",
    "    ax1.plot(x, model, label='Fit')\n",
    "    ax1.legend(loc='best', fontsize=15.0)\n",
    "\n",
    "    ax2.set_ylabel(r'Ratio', fontsize = 15.0)\n",
    "    ax2.set_ylim(0.5,1.5)\n",
    "    ax2.axhline(y=1.)\n",
    "\n",
    "    ax2.errorbar(x, y/model, yerr=y_err/model, fmt='o', capsize=2)\n",
    "\n",
    "    ax2.set_xlabel('Rate [cts/s]', fontsize = 15.0)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.1)\n",
    "    \n",
    "    if not bkg:\n",
    "        plt.savefig(figures_path+f'{ObsID}_{instrument}_rate_fit.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(figures_path+f'{instrument}_bkg_rate_fit.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(instrument, analysis_path, ObsID, bkg=False):\n",
    "    # Change to instrument directory\n",
    "    if(instrument == 'EPN'):\n",
    "        os.chdir(instrument + '/Main/')\n",
    "    else:\n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    # Load file and data\n",
    "    if not bkg:\n",
    "        fname = 'rate_' + instrument + '.fits'\n",
    "    else:\n",
    "        fname = 'rate_' + instrument + '_bkg.fits'\n",
    "        \n",
    "    hdul = fits.open(fname)\n",
    "    data = hdul[1].data\n",
    "\n",
    "    time = data['time']\n",
    "    rate = data['rate']\n",
    "    rate_err = data['error']\n",
    "\n",
    "    hdul.close()\n",
    "    os.chdir(analysis_path)\n",
    "    \n",
    "    # Delete zero rates\n",
    "    where = np.where(rate == 0)[0]\n",
    "\n",
    "    time = np.delete(time, where)\n",
    "    rate = np.delete(rate, where)\n",
    "    rate_err = np.delete(rate_err, where)\n",
    "    \n",
    "    # Make histogram\n",
    "    hist, bin_edges = np.histogram(np.log10(rate), bins=20)\n",
    "        \n",
    "    bin_mid = 0.5*(bin_edges[1:] + bin_edges[:-1])\n",
    "    bin_mid = 10**(bin_mid)\n",
    "    hist_err = np.sqrt(hist)\n",
    "    \n",
    "    # Delete zero counts in bins\n",
    "    where = np.where(hist_err == 0)[0]\n",
    "\n",
    "    bin_mid = np.delete(bin_mid, where)\n",
    "    hist = np.delete(hist, where)\n",
    "    hist_err = np.delete(hist_err, where)\n",
    "    \n",
    "    # Define gaussian function\n",
    "    gaussian = lambda x, amp, cen, sig: amp * np.exp(-(x-cen)**2 / sig**2)\n",
    "\n",
    "    # Fit\n",
    "    init_vals = [max(hist), np.mean(bin_mid), np.std(bin_mid)]\n",
    "    \n",
    "    best_vals, covar = curve_fit(gaussian, bin_mid, hist, p0=init_vals, sigma=1/hist_err, bounds=((0, 0, 0),\n",
    "                                                                                        (np.inf, np.inf, np.inf)),\n",
    "                                maxfev=100000)\n",
    "    # Plot\n",
    "    if not bkg:\n",
    "        plotting(bin_mid, hist, hist_err, gaussian(bin_mid, *best_vals), \n",
    "                 [best_vals[1]-2*best_vals[2], best_vals[1]+2*best_vals[2]], ObsID, \n",
    "                 instrument, figures_path)\n",
    "    else:\n",
    "        plotting(bin_mid, hist, hist_err, gaussian(bin_mid, *best_vals), \n",
    "                 [best_vals[1]-2*best_vals[2], best_vals[1]+2*best_vals[2]], ObsID, \n",
    "                 instrument, figures_path, bkg=True)\n",
    "    \n",
    "    return best_vals[1], best_vals[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highly flared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flared_fit(instrument, analysis_path, ObsID, EMOS_cts_limit = 0.6, bkg=False):\n",
    "    # Change to instrument directory\n",
    "    if(instrument == 'EPN'):\n",
    "        os.chdir(instrument + '/Main/')\n",
    "    else:\n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    # Load file and data\n",
    "    if not bkg:\n",
    "        fname = 'rate_' + instrument + '.fits'\n",
    "    else:\n",
    "        fname = 'rate_' + instrument + '_bkg.fits'\n",
    "        \n",
    "    hdul = fits.open(fname)\n",
    "    data = hdul[1].data\n",
    "\n",
    "    time = data['time']\n",
    "    rate = data['rate']\n",
    "    rate_err = data['error']\n",
    "\n",
    "    hdul.close()\n",
    "    os.chdir(analysis_path)\n",
    "    \n",
    "    # Delete zero rates\n",
    "    where = np.where(rate == 0)[0]\n",
    "\n",
    "    time = np.delete(time, where)\n",
    "    rate = np.delete(rate, where)\n",
    "    rate_err = np.delete(rate_err, where)\n",
    "    \n",
    "    # Make histogram\n",
    "    hist, bin_edges = np.histogram(np.log10(rate), bins=50)\n",
    "        \n",
    "    bin_mid = 0.5*(bin_edges[1:] + bin_edges[:-1])\n",
    "    bin_mid = 10**(bin_mid)\n",
    "    hist_err = np.sqrt(hist)\n",
    "    \n",
    "    # Delete zero counts in bins\n",
    "    where = np.where(hist_err == 0)[0]\n",
    "\n",
    "    bin_mid = np.delete(bin_mid, where)\n",
    "    hist = np.delete(hist, where)\n",
    "    hist_err = np.delete(hist_err, where)\n",
    "    \n",
    "    # Define gaussian function\n",
    "    gaussian = lambda x, amp, cen, sig: amp * np.exp(-(x-cen)**2 / sig**2)\n",
    "\n",
    "    # Fit\n",
    "    best_vals = [max(hist), np.mean(bin_mid), np.std(bin_mid)]\n",
    "    \n",
    "    for i in range(2):\n",
    "        best_vals, covar = curve_fit(gaussian, bin_mid, hist, p0=best_vals, sigma=1/hist_err, bounds=((0, 0, 0),\n",
    "                                                                                        (np.inf, np.inf, np.inf)),\n",
    "                                maxfev=10000)\n",
    "        \n",
    "        if(instrument == 'EPN'):\n",
    "            hist = hist[bin_mid < 1.3]\n",
    "            hist_err = hist_err[bin_mid < 1.3]\n",
    "            bin_mid = bin_mid[bin_mid < 1.3]\n",
    "            \n",
    "        else:\n",
    "            hist = hist[bin_mid < EMOS_cts_limit]\n",
    "            hist_err = hist_err[bin_mid < EMOS_cts_limit]\n",
    "            bin_mid = bin_mid[bin_mid < EMOS_cts_limit]\n",
    "        \n",
    "    # Plot\n",
    "    if not bkg:\n",
    "        plotting(bin_mid, hist, hist_err, gaussian(bin_mid, *best_vals), \n",
    "                 [best_vals[1]-2*best_vals[2], best_vals[1]+2*best_vals[2]], ObsID, \n",
    "                 instrument, figures_path)\n",
    "    else:\n",
    "        plotting(bin_mid, hist, hist_err, gaussian(bin_mid, *best_vals), \n",
    "                 [best_vals[1]-2*best_vals[2], best_vals[1]+2*best_vals[2]], ObsID, \n",
    "                 instrument, figures_path, bkg=True)\n",
    "    \n",
    "    return best_vals[1], best_vals[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make GTI and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gti_filter(instrument, analysis_path, mean, sigma, OoT=False):\n",
    "    # Keep log file \n",
    "    f = open(analysis_path + instrument + '_filter.txt', 'w')\n",
    "    \n",
    "    if(instrument == 'EPN'):\n",
    "        if(OoT):\n",
    "            os.chdir(instrument + '/OoT/')\n",
    "            os.rename(f.name, analysis_path + instrument + '_OoT_filter.txt')\n",
    "        else:\n",
    "            os.chdir(instrument + '/Main/')\n",
    "            os.rename(f.name, analysis_path + instrument + '_main_filter.txt')\n",
    "    else:\n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    # Create GTI and filter\n",
    "    fname = 'rate_' + instrument + '.fits'\n",
    "    \n",
    "    s.run(['tabgtigen', f'table={fname}', f'expression=RATE<={mean+2*sigma}', f'gtiset={instrument}_gti.fits'], \n",
    "          stdout=f, stderr=f)\n",
    "\n",
    "    fname = glob.glob('*_ImagingEvts.ds')[0]\n",
    "    \n",
    "    s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_clean.fits', \n",
    "            'destruct=Y', 'keepfilteroutput=T', \n",
    "            f'expression=#XMMEA_{instrument} && gti({instrument}_gti.fits,TIME) && (PI>150)'], stdout=f,stderr=f)\n",
    "         \n",
    "    f.close()\n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(instrument, analysis_path, OoT=False):\n",
    "    # Keep log file \n",
    "    f = open(analysis_path + instrument + '_image.txt', 'w')\n",
    "    \n",
    "    if(instrument == 'EPN'):\n",
    "        pattern = 4\n",
    "        \n",
    "        if(OoT):\n",
    "            os.chdir(instrument + '/OoT/')\n",
    "            os.rename(f.name, analysis_path + instrument + '_OoT_image.txt')\n",
    "        else:\n",
    "            os.chdir(instrument + '/Main/')\n",
    "            os.rename(f.name, analysis_path + instrument + '_main_image.txt')\n",
    "    else:\n",
    "        pattern = 12\n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    # Create image\n",
    "    fname = instrument + '_clean.fits'\n",
    "    \n",
    "    s.run(['evselect', f'table={fname}', 'xcolumn=X', 'ycolumn=Y', 'imagebinning=binSize', 'ximagebinsize=80',\n",
    "            'yimagebinsize=80', 'withimageset=true', f'imageset={instrument}_counts_nr.img', \n",
    "            f'expression=#XMMEA_{instrument[:2]}&&(PATTERN<={pattern})&&(PI>=500)&&(PI<=7000)'], stdout=f, stderr=f)\n",
    "        \n",
    "    # Create exposure map\n",
    "    fname = glob.glob('*_AttHk.ds')[0]\n",
    "    \n",
    "    s.run(['eexpmap', f'imageset={instrument}_counts_nr.img', f'attitudeset={fname}', \n",
    "           f'eventset={instrument}_clean.fits', f'expimageset={instrument}_exp_nr.img', 'pimin=500', 'pimax=7000'],\n",
    "           stdout=f, stderr=f)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OoT image correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oot_corr(frame, analysis_path):\n",
    "    # Keep log file \n",
    "    f = open(analysis_path + 'EPN_oot_image_corr.txt', 'w')\n",
    "    os.chdir(analysis_path + 'EPN/OoT/')\n",
    "    \n",
    "    # Scale OoT image\n",
    "    if(frame == 'eff'):\n",
    "        s.run(['farith', 'EPN_counts.img', '0.023', 'EPN_rescaled_counts.img', 'MUL', 'clobber=yes'], \n",
    "              stdout=f, stderr=f)\n",
    "        \n",
    "    elif(frame == 'ff'):\n",
    "        s.run(['farith', 'EPN_counts.img', '0.063', 'EPN_rescaled_counts.img', 'MUL', 'clobber=yes'], \n",
    "              stdout=f, stderr=f)\n",
    "        \n",
    "    # Subtract from PN image\n",
    "    os.chdir(analysis_path + 'EPN/main/')\n",
    "    \n",
    "    fname = analysis_path + 'EPN/OoT/EPN_rescaled_counts.img'\n",
    "    s.run(['farith', 'EPN_counts.img', f'{fname}', 'EPN_corr_counts.img', 'SUB', 'clobber=yes'], \n",
    "          stdout=f, stderr=f)\n",
    "    \n",
    "    f.close()\n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproject background files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkg_reprojection(cluster, instrument, inst_filter, analysis_path):\n",
    "    # Keep log file \n",
    "    f = open(analysis_path + instrument + '_bkg_reproject.txt', 'w')\n",
    "    \n",
    "    if(instrument == 'EPN'):\n",
    "        os.chdir(instrument + '/Main/')\n",
    "        os.rename(f.name, analysis_path + instrument + '_bkg_main_reproject.txt')\n",
    "    else:\n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    # Read in key headers\n",
    "    fname = analysis_path + f'EMOS1/EMOS1_clean.fits'\n",
    "    hdul = fits.open(fname)\n",
    "    data = hdul[0].header\n",
    "\n",
    "    ra = data['ra_pnt']\n",
    "    dec = data['dec_pnt']\n",
    "    pa = data['pa_pnt']\n",
    "\n",
    "    hdul.close()\n",
    "    \n",
    "    # Locate the bkg file first\n",
    "    bkg_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Data/'\n",
    "    \n",
    "    if((instrument == 'EPN') and (frame == 'eff')):\n",
    "        if(inst_filter == 't'):\n",
    "            fname = glob.glob(bkg_path + instrument + 'tef*')[0]\n",
    "    \n",
    "        elif(inst_filter == 'm'):\n",
    "            fname = glob.glob(bkg_path + instrument + 'mef*')[0]\n",
    "            \n",
    "    elif((instrument == 'EPN') and (frame == 'ff')):\n",
    "        if(inst_filter == 't'):\n",
    "            fname = glob.glob(bkg_path + instrument + 'tff*')[0]\n",
    "    \n",
    "        elif(inst_filter == 'm'):\n",
    "            fname = glob.glob(bkg_path + instrument + 'mff*')[0]\n",
    "            \n",
    "    else:\n",
    "        if(inst_filter == 't'):\n",
    "            fname = glob.glob(bkg_path + instrument + 't*')[0]\n",
    "    \n",
    "        elif(inst_filter == 'm'):\n",
    "            fname = glob.glob(bkg_path + instrument + 'm*')[0]\n",
    "        \n",
    "    # Copy the necessary background file\n",
    "    s.run(['cp', f'{fname}', f'{instrument}_bkg_evt.fits'], stdout=f,stderr=f)\n",
    "        \n",
    "    # Then reproject\n",
    "    s.run(['evproject', f'eventset={instrument}_bkg_evt.fits', 'attsource=fixed', f'attra={ra}', f'attdec={dec}', \n",
    "           f'attapos={pa}'], stdout=f,stderr=f)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkg_lc(instrument, analysis_path):\n",
    "    os.chdir(instrument)\n",
    "    \n",
    "    # Keep log file in analysis directory\n",
    "    f = open(analysis_path + instrument + '_bkg_lc.txt', 'w')\n",
    "    \n",
    "    # Check which instrument is requested and process accordingly\n",
    "    if(instrument == 'EPN'):\n",
    "        os.chdir('Main')\n",
    "        pattern = 4\n",
    "    else:\n",
    "        pattern = 12\n",
    "    \n",
    "    fname = instrument + '_bkg_evt.fits'\n",
    "\n",
    "    s.run(['evselect', f'table={fname}', 'withrateset=Y', f'rateset=rate_{instrument}_bkg.fits', \n",
    "            'maketimecolumn=Y', 'timebinsize=100', 'makeratecolumn=Y', \n",
    "            f'expression=#XMMEA_{instrument[:2]} && (PI in [9000:12000]) && (PATTERN<={pattern})'], \n",
    "          stdout=f, stderr=f)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkg_gti_filter(instrument, analysis_path, mean, sigma):\n",
    "    # Keep log file \n",
    "    f = open(analysis_path + instrument + '_bkg_filter.txt', 'w')\n",
    "    \n",
    "    if(instrument == 'EPN'):\n",
    "        os.chdir(instrument + '/Main/')\n",
    "        os.rename(f.name, analysis_path + instrument + '_bkg_filter.txt')\n",
    "    else:\n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    # Create GTI and filter\n",
    "    fname = 'rate_' + instrument + '_bkg.fits'\n",
    "    \n",
    "    s.run(['tabgtigen', f'table={fname}', f'expression=RATE<={mean+2*sigma}', f'gtiset={instrument}_bkg_gti.fits'], \n",
    "          stdout=f, stderr=f)\n",
    "    \n",
    "    fname = instrument + '_bkg_evt.fits'\n",
    "    \n",
    "    s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_bkg_clean.fits', \n",
    "            'destruct=Y', 'keepfilteroutput=T', \n",
    "            f'expression=#XMMEA_{instrument[:2]} && gti({instrument}_bkg_gti.fits,TIME) && (PI>150)'], \n",
    "            stdout=f,stderr=f)\n",
    "    \n",
    "    # Create OofFOV file as well\n",
    "    s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_bkg_oofov.fits', \n",
    "            'destruct=Y', 'keepfilteroutput=T', \n",
    "            f'expression=#XMMEA_16 && gti({instrument}_bkg_gti.fits,TIME) && (PI>150)'], \n",
    "            stdout=f,stderr=f)\n",
    "         \n",
    "    f.close()\n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate scaling factor for background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkg_scaling(cluster, instrument, analysis_path, after_2005 = False):\n",
    "    # Keep log file \n",
    "    f = open(analysis_path + instrument + '_bkg_scaling.txt', 'w')\n",
    "    \n",
    "    if(instrument == 'EPN'):\n",
    "        pattern = 4\n",
    "        \n",
    "        os.chdir(instrument + '/Main/')\n",
    "        os.rename(f.name, analysis_path + instrument + '_bkg_main_scaling.txt')\n",
    "    else:\n",
    "        pattern = 12\n",
    "        \n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    #-------------------------------- BACKGROUND ANALYSIS -----------------------------------\n",
    "    bkg_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Data/'\n",
    "    region_file = bkg_path + instrument + 'fwc.cxc'\n",
    "    \n",
    "    fname = f'{instrument}_bkg_oofov.fits'\n",
    "    \n",
    "    # Account for loss of EMOS1 CCDs afer and before 2005\n",
    "    if(instrument == 'EMOS1'):\n",
    "        if(after_2005):\n",
    "            s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_bkgtime_oofov.fits', \n",
    "                    'destruct=Y', 'keepfilteroutput=T', \n",
    "                    f'expression=#XMMEA_16&&(PATTERN<={pattern})&&(PI in [9000:12000])\\\n",
    "                    &&(CCDNR.ne.6)\\\n",
    "                    &&region({region_file})'], stdout=f, stderr=f)\n",
    "            \n",
    "            s.run(['evselect', f'table={instrument}_bkgtime_oofov.fits', 'xcolumn=X', 'ycolumn=Y', \n",
    "                   'imagebinning=binSize', 'ximagebinsize=20', 'yimagebinsize=20', 'withimageset=true', \n",
    "                   f'imageset={instrument}_oofov_bkg_counts.img'], stdout=f, stderr=f)\n",
    "            \n",
    "        else:\n",
    "            # Constraining the bkg events uptil 2005\n",
    "            s.run(['evselect', f'table={fname}', 'withrateset=Y', f'rateset=rate_{instrument}_bkgclean.fits', \n",
    "                    'maketimecolumn=Y', 'timebinsize=100', 'makeratecolumn=Y', \n",
    "                    f'expression=#XMMEA_16&&(PI in [9000:12000])&&(PATTERN<={pattern})'], \n",
    "                      stdout=f, stderr=f)\n",
    "            \n",
    "            s.run(['tabgtigen', f'table=rate_{instrument}_bkgclean.fits', f'expression=TIME<226713600', \n",
    "                   f'gtiset={instrument}_bkgtime_gti.fits'], stdout=f, stderr=f)\n",
    "            \n",
    "            \n",
    "            # Then filtering\n",
    "            s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_bkgtime_oofov.fits', \n",
    "                    'destruct=Y', 'keepfilteroutput=T', \n",
    "                    f'expression=#XMMEA_16&&(PATTERN<={pattern})&&(PI in [9000:12000])&&\\\n",
    "                    gti({instrument}_bkgtime_gti.fits,TIME)&&region({region_file})'], stdout=f, stderr=f)\n",
    "            \n",
    "            s.run(['evselect', f'table={instrument}_bkgtime_oofov.fits', 'xcolumn=X', 'ycolumn=Y', \n",
    "                   'imagebinning=binSize', 'ximagebinsize=20', 'yimagebinsize=20', 'withimageset=true', \n",
    "                   f'imageset={instrument}_oofov_bkg_counts.img'], stdout=f, stderr=f)\n",
    "    \n",
    "    # Others get processed normally\n",
    "    elif(instrument == 'EMOS2'):\n",
    "        s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_bkgtime_oofov.fits', \n",
    "                'destruct=Y', 'keepfilteroutput=T', \n",
    "                f'expression=#XMMEA_16&&(PATTERN<={pattern})&&(PI in [9000:12000])&&region({region_file})'], \n",
    "                stdout=f, stderr=f)\n",
    "            \n",
    "        s.run(['evselect', f'table={instrument}_bkgtime_oofov.fits', 'xcolumn=X', 'ycolumn=Y', \n",
    "                'imagebinning=binSize', 'ximagebinsize=20', 'yimagebinsize=20', 'withimageset=true', \n",
    "                f'imageset={instrument}_oofov_bkg_counts.img'], stdout=f, stderr=f)\n",
    "    \n",
    "    else:\n",
    "        fname = f'{instrument}_bkg_clean.fits'\n",
    "        \n",
    "        s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_bkgtime_oofov.fits', \n",
    "                'destruct=Y', 'keepfilteroutput=T', \n",
    "                f'expression=#XMMEA_EP&&(PATTERN<={pattern})&&(PI in [9000:12000])'], \n",
    "                stdout=f, stderr=f)\n",
    "            \n",
    "        s.run(['evselect', f'table={instrument}_bkgtime_oofov.fits', 'xcolumn=X', 'ycolumn=Y', \n",
    "                'imagebinning=binSize', 'ximagebinsize=20', 'yimagebinsize=20', 'withimageset=true', \n",
    "                f'imageset={instrument}_oofov_bkg_counts.img'], stdout=f, stderr=f)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Calculate background counts\n",
    "    fname = instrument + '_oofov_bkg_counts.img'\n",
    "    hdul = fits.open(fname)\n",
    "    data = hdul[0].data\n",
    "\n",
    "    bkg_counts = np.sum(data)\n",
    "    hdul.close()\n",
    "    \n",
    "    # Read livetime for bkg\n",
    "    fname = f'{instrument}_bkgtime_oofov.fits'\n",
    "    hdul = fits.open(fname)\n",
    "    data = hdul[1].header\n",
    "\n",
    "    bkg_livetime = data['LIVETI02']\n",
    "    \n",
    "    hdul.close()\n",
    "    \n",
    "    #-------------------------------- OBSERVATION ANALYSIS ---------------------------------------------------\n",
    "    fname = glob.glob('*_ImagingEvts.ds')[0]\n",
    "    \n",
    "    # Create an oofov event file as well\n",
    "    bkg_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Data/'\n",
    "    region_file = bkg_path + instrument + 'fwc.cxc'\n",
    "        \n",
    "    if(instrument == 'EPN'):\n",
    "        s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_oofov_clean.fits', \n",
    "            'destruct=Y', 'keepfilteroutput=T', \n",
    "            f'expression=#XMMEA_16&&(PATTERN<={pattern})&&(PI in [9000:12000])&&gti({instrument}_gti.fits,TIME)\\\n",
    "            &&(PI>150)'], stdout=f,stderr=f)\n",
    "    \n",
    "        s.run(['evselect', f'table={instrument}_oofov_clean.fits', 'xcolumn=X', 'ycolumn=Y', 'imagebinning=binSize', \n",
    "               'ximagebinsize=20', 'yimagebinsize=20', 'withimageset=true', f'imageset={instrument}_oofov_counts.img'],\n",
    "               stdout=f, stderr=f)\n",
    "    \n",
    "    else:\n",
    "        s.run(['evselect', f'table={fname}', 'withfilteredset=Y', f'filteredset={instrument}_oofov_clean.fits', \n",
    "                'destruct=Y', 'keepfilteroutput=T', \n",
    "                f'expression=#XMMEA_16&&(PATTERN<={pattern})&&(PI in [9000:12000])&&gti({instrument}_gti.fits,TIME)&&\\\n",
    "                region({region_file})&&(PI>150)'], stdout=f,stderr=f)\n",
    "    \n",
    "        s.run(['evselect', f'table={instrument}_oofov_clean.fits', 'xcolumn=X', 'ycolumn=Y', 'imagebinning=binSize', \n",
    "               'ximagebinsize=20', 'yimagebinsize=20', 'withimageset=true', f'imageset={instrument}_oofov_counts.img'],\n",
    "               stdout=f, stderr=f)\n",
    "        \n",
    "    # Read the counts\n",
    "    fname = instrument + '_oofov_counts.img'\n",
    "    hdul = fits.open(fname)\n",
    "    data = hdul[0].data\n",
    "\n",
    "    obs_counts = np.sum(data)\n",
    "    \n",
    "    hdul.close()\n",
    "    \n",
    "    # Read livetime for source\n",
    "    fname = instrument + '_oofov_clean.fits'\n",
    "    hdul = fits.open(fname)\n",
    "    data = hdul[1].header\n",
    "\n",
    "    obs_livetime = data['LIVETI02']\n",
    "    \n",
    "    hdul.close()\n",
    "    \n",
    "    f.close()\n",
    "    os.chdir(analysis_path)\n",
    "    \n",
    "    #print( (bkg_counts/bkg_livetime) / (obs_counts/obs_livetime) )\n",
    "    return bkg_counts / obs_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image production background files, scaling, subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkg_image(instrument, analysis_path, scaling, after_2005=False):\n",
    "    # Keep log file \n",
    "    f = open(analysis_path + instrument + '_bkg_image.txt', 'w')\n",
    "    \n",
    "    if(instrument == 'EPN'):\n",
    "        pattern = 4\n",
    "        imgname = 'EPN_corr_counts_nr.img'\n",
    "        \n",
    "        os.chdir(instrument + '/Main/')\n",
    "        os.rename(f.name, analysis_path + instrument + '_bkg_image.txt')\n",
    "    else:\n",
    "        pattern = 12\n",
    "        imgname = f'{instrument}_counts.img'\n",
    "        \n",
    "        os.chdir(instrument)\n",
    "        \n",
    "    # Create image\n",
    "    fname = instrument + '_bkg_clean.fits'\n",
    "    \n",
    "    if((instrument == 'EMOS1') and (after_2005 == True)):\n",
    "        s.run(['evselect', f'table={fname}', 'xcolumn=X', 'ycolumn=Y', 'imagebinning=binSize', 'ximagebinsize=20',\n",
    "                'yimagebinsize=20', 'withimageset=true', f'imageset={instrument}_bkg_counts.img', \n",
    "                f'expression=(#XMMEA_{instrument[:2]})&&(PATTERN<={pattern})&&(PI in [500:7000])\\\n",
    "                &&(CCDNR.ne.6)'], stdout=f, stderr=f)\n",
    "        \n",
    "    else:\n",
    "        s.run(['evselect', f'table={fname}', 'xcolumn=X', 'ycolumn=Y', 'imagebinning=binSize', 'ximagebinsize=20',\n",
    "                'yimagebinsize=20', 'withimageset=true', f'imageset={instrument}_bkg_counts.img', \n",
    "                f'expression=#XMMEA_{instrument[:2]}&&(PATTERN<={pattern})&&(PI in [500:7000])'], \n",
    "              stdout=f, stderr=f)\n",
    "          \n",
    "    # Add header\n",
    "    s.run(['fparkey', f'{1/scaling}', f'{instrument}_bkg_counts.img[0]', f'bkgnorm', 'add=yes'], stdout=f, stderr=f)\n",
    "    \n",
    "    # Scaling\n",
    "    #s.run(['farith', f'{instrument}_bkg_counts.img', f'{scaling}', f'{instrument}_rescaled_bkg_counts.img', \n",
    "    #       'DIV', 'clobber=yes'], stdout=f, stderr=f)\n",
    "    \n",
    "    # Subtraction\n",
    "    #s.run(['farith', f'{imgname}', f'{instrument}_rescaled_bkg_counts.img', f'{instrument}_bkgsub_counts.img', \n",
    "    #       'SUB', 'null=yes', 'blank=0', 'clobber=yes'], stdout=f, stderr=f)\n",
    "    \n",
    "    # Exposure correction\n",
    "    #s.run(['farith', f'{instrument}_bkgsub_counts.img', f'{instrument}_exp.img', f'{instrument}_flux.img', \n",
    "    #       'DIV', 'clobber=yes'], stdout=f, stderr=f)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    os.chdir(analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image(cluster, img_paths, exp_paths, destination, instrument):\n",
    "    # Keep log file \n",
    "    f = open(destination + instrument + '_add_image.txt', 'w')\n",
    "    \n",
    "    if (len(img_paths) is not len(exp_paths)):\n",
    "        raise ValueError(\"Number of images and exposures must be same\")\n",
    "    \n",
    "    images = \" \".join(img_paths)\n",
    "    exposures = \" \".join(exp_paths)\n",
    "    \n",
    "    s.run(['emosaic', f'imagesets={images}', f'mosaicedset={destination}{instrument}_{cluster}_exp_nr.img', \n",
    "           'withexposure=no'], stdout=f, stderr=f)\n",
    "    \n",
    "    #s.run(['emosaic', f'imagesets={images}', f'mosaicedset={destination}{instrument}_{cluster}_exp_corr_nr.img', \n",
    "    #       'withexposure=yes', f'exposuresets={exposures}'], stdout=f, stderr=f)\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 'MACS J2135.2-0102'\n",
    "instruments = ['EMOS1', 'EMOS2']\n",
    "\n",
    "figures_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/figures/'\n",
    "\n",
    "# Make appropriate directories\n",
    "data_base = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Data/XMM_obs/'\n",
    "analysis_base = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Analysis/'\n",
    "\n",
    "mkdir(data_base)\n",
    "mkdir(analysis_base)\n",
    "mkdir(figures_path)\n",
    "\n",
    "# Check XMM data\n",
    "check_data(data_base, analysis_base, cluster, radius=1000)\n",
    "\n",
    "# Read obsids\n",
    "ObsIDs = np.loadtxt(data_base + 'check_data.txt', dtype=str, skiprows=5, delimiter='|', usecols=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0021540501', '0021540101', '0723800201', '0723800101'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ObsIDs = ObsIDs[:-1]\n",
    "ObsIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ObsIDs = np.delete(ObsIDs,-2)\n",
    "ObsID = ObsIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, ObsID in enumerate(ObsIDs):\n",
    "    data_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Data/XMM_obs/{ObsID}/'\n",
    "    analysis_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Analysis/{ObsID}/'\n",
    "    \n",
    "    #mkdir(data_path)\n",
    "    #mkdir(analysis_path)\n",
    "    \n",
    "    # Change to data directory\n",
    "    #os.chdir(data_path)\n",
    "    \n",
    "    # Download the data\n",
    "    #download_data(ObsID)\n",
    "    \n",
    "    # Unpack data\n",
    "    #unpack(ObsID)\n",
    "\n",
    "    # Change to analysis directory\n",
    "    os.chdir(analysis_path)\n",
    "    \n",
    "    # Set the environment\n",
    "    #calib(data_path, analysis_path)\n",
    "    set_environ(analysis_path)\n",
    "\n",
    "    # Reprocess instruments\n",
    "    #for instrument in instruments:\n",
    "    #    reprocess(instrument, analysis_path)\n",
    "\n",
    "    # Create light curves\n",
    "    #for instrument in instruments:\n",
    "    #    lc(instrument, analysis_path)\n",
    "\n",
    "    # Fit gaussian, plot and filter\n",
    "    #for instrument in instruments:\n",
    "    #    mean, sigma = fit(instrument, analysis_path, ObsID)\n",
    "    #    mean, sigma = flared_fit(instrument, analysis_path, ObsID, 0.5)\n",
    "    #    print(f'ObsID: {ObsID}; instrument: {instrument}; Mean =  {mean}; sigma = {sigma}')\n",
    "    #    gti_filter(instrument, analysis_path, mean, sigma)\n",
    "        \n",
    "        #break\n",
    "    \n",
    "    # Create images\n",
    "    for instrument in instruments:\n",
    "        image(instrument, analysis_path)\n",
    "    \n",
    "    # Reproject background files\n",
    "    #for instrument in instruments:\n",
    "    #    bkg_reprojection(cluster, instrument, inst_filter[i], analysis_path)\n",
    "    \n",
    "    # Filter background files\n",
    "    # Create light curves\n",
    "    #for instrument in instruments:\n",
    "    #    bkg_lc(instrument, analysis_path)\n",
    "        #break\n",
    "\n",
    "    # Fit gaussian, plot and filter\n",
    "    #for instrument in instruments:\n",
    "    #    mean, sigma = fit(instrument, analysis_path, ObsID, bkg=True)\n",
    "    #    print(f'Mean =  {mean}; sigma = {sigma}')\n",
    "    #    bkg_gti_filter(instrument, analysis_path, mean, sigma)\n",
    "        \n",
    "        #break\n",
    "    \n",
    "    # Calculate scaling factor\n",
    "    #for instrument in instruments:\n",
    "    #    scaling = bkg_scaling(cluster, instrument, analysis_path, after_2005s[i])\n",
    "    #    print('Bkg cts/Src cts [9-12 keV OoFOV]: ', scaling)\n",
    "    #    bkg_image(instrument, analysis_path, scaling, after_2005s[i])\n",
    "        #break\n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('0146510301', dtype='<U10')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ObsID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add images\n",
    "added_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Analysis/'\n",
    "img_path = []\n",
    "exp_path = []\n",
    "\n",
    "for ObsID in ObsIDs:\n",
    "    img_path.append(f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Analysis/{ObsID}/EMOS1/EMOS1_counts_nr.img')\n",
    "    img_path.append(f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Analysis/{ObsID}/EMOS2/EMOS2_counts_nr.img')\n",
    "                    \n",
    "    exp_path.append(f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Analysis/{ObsID}/EMOS1/EMOS1_exp_nr.img')\n",
    "    exp_path.append(f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster.replace(\" \", \"_\")}/Analysis/{ObsID}/EMOS2/EMOS2_exp_nr.img')\n",
    "        \n",
    "#add_image(cluster, img_path, exp_path, added_path, 'EMOS')\n",
    "add_image(cluster, exp_path, exp_path, added_path, 'EMOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/Cygnus_A/Analysis/0302800201/EMOS1/EMOS1_exp_nr.img',\n",
       " '/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/Cygnus_A/Analysis/0302800201/EMOS2/EMOS2_exp_nr.img',\n",
       " '/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/Cygnus_A/Analysis/0302800101/EMOS1/EMOS1_exp_nr.img',\n",
       " '/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/Cygnus_A/Analysis/0302800101/EMOS2/EMOS2_exp_nr.img']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add bkgnorm parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-2ad4b7dd46ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexposure_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObsID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObsIDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Data/XMM_obs/{ObsID}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0manalysis_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Analysis/{ObsID}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "#scaling = np.array([])\n",
    "exposure = np.array([])\n",
    "exposure_source = np.array([])\n",
    "\n",
    "for i, ObsID in enumerate(ObsIDs):\n",
    "    data_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Data/XMM_obs/{ObsID}/'\n",
    "    analysis_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Analysis/{ObsID}/'\n",
    "\n",
    "    # Change to analysis directory\n",
    "    for instrument in instruments:\n",
    "        os.chdir(analysis_path+'/'+instrument)\n",
    "        \n",
    "        #fname = instrument + '_bkg_counts.img'\n",
    "        #hdul = fits.open(fname)\n",
    "        #data = hdul[0].header\n",
    "\n",
    "        #scaling = np.append(scaling, data['bkgnorm'])\n",
    "        #exposure = np.append(exposure, data['exposure'])\n",
    "    \n",
    "        #hdul.close()\n",
    "        \n",
    "        fname = instrument + '_counts.img'\n",
    "        hdul = fits.open(fname)\n",
    "        data = hdul[0].header\n",
    "\n",
    "        exposure_source = np.append(exposure_source, data['exposure'])\n",
    "    \n",
    "        hdul.close()\n",
    "        \n",
    "#weighted_norm = np.average(scaling, weights=exposure_source)\n",
    "#bkg_exposure = np.sum(exposure)\n",
    "src_exposure = np.sum(exposure_source)\n",
    "\n",
    "os.chdir(f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Analysis/')\n",
    "s.run(['fparkey', f'{1.}', f'EMOS_NGC5846_bkg_counts.img[0]', f'bkgnorm', 'add=yes'])\n",
    "s.run(['fparkey', f'{src_exposure}', f'EMOS_NGC5846_bkg_counts.img[0]', f'exposure', 'add=yes'])\n",
    "s.run(['fparkey', f'{src_exposure}', f'EMOS_NGC5846_counts.img[0]', f'exposure', 'add=yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsharp masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 'Phoenix'\n",
    "added_path = f'/Users/anweshmajumder/Desktop/Grad/My_papers/Paper-2/{cluster}/Analysis/'\n",
    "\n",
    "fname = added_path + f'EMOS_Phoenix_wops_exp_corr.img'\n",
    "hdul = fits.open(fname)\n",
    "data = hdul[0].data\n",
    "header = hdul[0].header\n",
    "    \n",
    "hdul.close()\n",
    "\n",
    "smooth_1_data = gaussian_filter(data, sigma=1)\n",
    "smooth_10_data = gaussian_filter(data, sigma=4)\n",
    "\n",
    "unsharp_data = smooth_1_data - smooth_10_data\n",
    "\n",
    "hdu = fits.PrimaryHDU(unsharp_data, header)\n",
    "hdu.writeto(added_path + f'EMOS_{cluster}_unsharp_1.img', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = added_path + f'EMOS_{cluster}_unsharp_1.img'\n",
    "hdul = fits.open(fname)\n",
    "data = hdul[0].data\n",
    "header = hdul[0].header\n",
    "    \n",
    "hdul.close()\n",
    "\n",
    "smooth_data = gaussian_filter(data, sigma=0.7)\n",
    "\n",
    "hdu = fits.PrimaryHDU(smooth_data, header)\n",
    "hdu.writeto(added_path + f'EMOS_{cluster}_unsharp_smooth.img', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
